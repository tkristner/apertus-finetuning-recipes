# ğŸ§® Guide MetaMathQA - AmÃ©liorer le Raisonnement MathÃ©matique

## ProblÃ¨me IdentifiÃ©

Les deux modÃ¨les (BASE et fine-tunÃ©) donnent des **rÃ©ponses incorrectes** sur le problÃ¨me de trains:

### âŒ RÃ©ponse Correcte Attendue
**Question:** Un train part de Paris Ã  14h Ã  120 km/h. Un autre part de Lyon (450 km) Ã  14h30 Ã  100 km/h vers Paris. Quand se croisent-ils?

**Calcul correct:**
1. Ã€ 14h30, le train de Paris a dÃ©jÃ  parcouru: 120 km/h Ã— 0.5h = 60 km
2. Distance restante: 450 - 60 = 390 km
3. Vitesse d'approche: 120 + 100 = 220 km/h
4. Temps pour se croiser: 390 / 220 = 1.77 heures â‰ˆ 1h46min
5. **Heure de croisement: 14h30 + 1h46 = 16h16**
6. **Distance de Paris: 60 + (120 Ã— 1.77) = 272 km**

### âŒ RÃ©ponses Actuelles des ModÃ¨les
- **BASE:** 18h Ã  400 km (complÃ¨tement faux)
- **FINE-TUNÃ‰:** 15h Ã  120 km (complÃ¨tement faux)

## Solution: IntÃ©grer MetaMathQA

MetaMathQA est un dataset de **395K problÃ¨mes mathÃ©matiques** avec raisonnement Ã©tape par Ã©tape.

---

## ğŸš€ Utilisation

### **Ã‰tape 1: PrÃ©parer MetaMathQA (20%)**

```bash
python prepare_metamath_dataset.py --ratio 0.2 --max-samples 10000
```

**Options:**
- `--ratio 0.2` â†’ 20% du dataset (â‰ˆ79K exemples, limitÃ© Ã  10K)
- `--max-samples 10000` â†’ Maximum 10K exemples
- `--output ./data/metamath_subset` â†’ RÃ©pertoire de sortie

**RÃ©sultat:**
- CrÃ©e `./data/metamath_subset/train.jsonl`
- ~10K exemples de problÃ¨mes mathÃ©matiques
- Format: Chat avec systÃ¨me prompt spÃ©cialisÃ© en maths

### **Ã‰tape 2: Combiner avec Votre Dataset (80% Custom / 20% Math)**

```bash
python prepare_metamath_dataset.py --ratio 0.2 --max-samples 10000 --combine --metamath-ratio 0.2
```

**RÃ©sultat:**
- CrÃ©e `./data/combined_dataset/train.jsonl`
- **80% de votre dataset RGPD** (prioritaire)
- **20% de MetaMathQA** (pour amÃ©liorer les maths)
- Format unifiÃ© avec systÃ¨me prompt adaptÃ©

**Personnaliser le ratio:**
```bash
# 70% Custom / 30% Math
python prepare_metamath_dataset.py --combine --metamath-ratio 0.3

# 90% Custom / 10% Math
python prepare_metamath_dataset.py --combine --metamath-ratio 0.1

# 50% Custom / 50% Math
python prepare_metamath_dataset.py --combine --metamath-ratio 0.5
```

### **Ã‰tape 3: Configurer le Fine-tuning**

CrÃ©ez ou modifiez `configs/sft_lora_combined.yaml`:

```yaml
# Model
model_name_or_path: swiss-ai/Apertus-8B-Instruct-2509
output_dir: Apertus-FT/output/apertus_lora_combined

# Dataset combinÃ© (RGPD + Math)
dataset_name: ./data/combined_dataset
dataset_train_split: train
dataset_test_split: train  # Pas de split test pour l'instant
dataset_num_proc: 12

# Hyperparameters
learning_rate: 5.0e-5
gradient_checkpointing: true
num_train_epochs: 3.0  # Moins d'epochs car plus de donnÃ©es
logging_steps: 1
eval_strategy: steps
eval_steps: 100
save_strategy: steps
save_steps: 200
per_device_train_batch_size: 4
gradient_accumulation_steps: 8
max_grad_norm: 0.5

# LoRA
use_peft: true
lora_r: 32
lora_alpha: 64
lora_dropout: 0.05
lora_target_modules: all-linear

# Training
bf16: true
max_seq_length: 2048
packing: false

# Optimizer
warmup_ratio: 0.1
lr_scheduler_type: cosine
min_lr_ratio: 0.05
```

### **Ã‰tape 4: Lancer le Fine-tuning**

```bash
python sft_train.py configs/sft_lora_combined.yaml
```

---

## ğŸ“Š Composition du Dataset CombinÃ© (Par DÃ©faut)

| Source | Exemples | Pourcentage | SpÃ©cialisation |
|--------|----------|-------------|----------------|
| **Custom RGPD** | ~500 | **80%** | Protection des donnÃ©es, RGPD |
| **MetaMathQA** | ~125 | **20%** | MathÃ©matiques, logique, raisonnement |
| **TOTAL** | ~625 | 100% | Multi-domaine |

**Note:** Le ratio est calculÃ© automatiquement en fonction de votre dataset custom.
- Si vous avez 500 exemples custom et `--metamath-ratio 0.2`, le script ajoutera ~125 exemples MetaMathQA
- Vous gardez **tous vos exemples custom** et le script ajuste MetaMathQA pour atteindre le ratio cible

---

## ğŸ¯ Avantages de MetaMathQA

âœ… **Raisonnement Ã©tape par Ã©tape:** Chaque problÃ¨me a une solution dÃ©taillÃ©e  
âœ… **DiversitÃ©:** AlgÃ¨bre, gÃ©omÃ©trie, arithmÃ©tique, logique  
âœ… **QualitÃ©:** Dataset crÃ©Ã© par Meta, haute qualitÃ©  
âœ… **Format cohÃ©rent:** Compatible avec votre pipeline  
âœ… **Taille contrÃ´lÃ©e:** 20% = ~10K exemples (pas trop volumineux)

---

## ğŸ“ˆ RÃ©sultats Attendus

### **Avant (modÃ¨le actuel):**
- âŒ ProblÃ¨me de trains: rÃ©ponse complÃ¨tement fausse
- âŒ Pas de raisonnement structurÃ©
- âŒ Erreurs de calcul basiques

### **AprÃ¨s (avec MetaMathQA):**
- âœ… Raisonnement Ã©tape par Ã©tape
- âœ… Calculs corrects
- âœ… Meilleure comprÃ©hension des problÃ¨mes de maths
- âœ… **Conservation des capacitÃ©s RGPD (80% du dataset)**

---

## ğŸ”§ Personnalisation

### **Ajuster le Ratio MetaMathQA**

**Par dÃ©faut (80% Custom / 20% Math):**
```bash
python prepare_metamath_dataset.py --combine --metamath-ratio 0.2
```

**Plus de maths (70% Custom / 30% Math):**
```bash
python prepare_metamath_dataset.py --combine --metamath-ratio 0.3
```

**Moins de maths (90% Custom / 10% Math):**
```bash
python prepare_metamath_dataset.py --combine --metamath-ratio 0.1
```

**Ã‰quilibrÃ© (50% Custom / 50% Math):**
```bash
python prepare_metamath_dataset.py --combine --metamath-ratio 0.5
```

### **SystÃ¨me Prompt PersonnalisÃ©**

Ã‰ditez `prepare_metamath_dataset.py` ligne 52:
```python
"content": "You are a helpful AI assistant specialized in mathematics and logical reasoning. Provide step-by-step solutions."
```

### **Filtrer par Type de ProblÃ¨me**

MetaMathQA contient diffÃ©rents types. Pour filtrer:
```python
# Dans prepare_metamath_dataset.py, ajoutez un filtre:
if example.get("type") in ["algebra", "arithmetic"]:
    # Traiter seulement ces types
```

---

## ğŸ§ª Tester le Nouveau ModÃ¨le

AprÃ¨s le fine-tuning:

```bash
# Test sur le problÃ¨me de trains
./test.sh --model Apertus-FT/output/apertus_lora_combined_YYYYMMDD_HHMMSS \
    --question "Un train part de Paris Ã  14h et roule Ã  120 km/h. Un autre train part de Lyon (450 km de Paris) Ã  14h30 et roule Ã  100 km/h vers Paris. Ã€ quelle heure et Ã  quelle distance de Paris se croiseront-ils?"

# Comparaison avec BASE
./test.sh --model Apertus-FT/output/apertus_lora_combined_YYYYMMDD_HHMMSS \
    --compare --benchmark
```

---

## ğŸ“ Exemple de Sortie MetaMathQA

**Question:**
```
Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?
```

**RÃ©ponse (avec raisonnement):**
```
Step 1: Calculate total eggs laid per day: 16 eggs
Step 2: Calculate eggs used for breakfast: 3 eggs
Step 3: Calculate eggs used for muffins: 4 eggs
Step 4: Calculate remaining eggs: 16 - 3 - 4 = 9 eggs
Step 5: Calculate revenue: 9 eggs Ã— $2 = $18

Answer: Janet makes $18 every day at the farmers' market.
```

---

## âš ï¸ ConsidÃ©rations

### **Taille du Dataset**
- 10K exemples â‰ˆ 2-3 heures de fine-tuning (selon GPU)
- Plus d'exemples = meilleur raisonnement mais plus long

### **Ã‰quilibre des Domaines**
- **Par dÃ©faut: 80% RGPD / 20% maths** - Conserve l'expertise RGPD tout en amÃ©liorant les maths
- Ajustez le ratio selon vos prioritÃ©s avec `--metamath-ratio`

### **SystÃ¨me Prompt**
- MetaMathQA utilise un prompt spÃ©cialisÃ© en maths
- Votre dataset RGPD utilise un prompt spÃ©cialisÃ© en protection des donnÃ©es
- Le modÃ¨le apprendra Ã  s'adapter selon le contexte

---

## ğŸ“ Workflow Complet

```bash
# 1. PrÃ©parer le dataset combinÃ© (80% Custom / 20% Math par dÃ©faut)
python prepare_metamath_dataset.py --ratio 0.2 --max-samples 10000 --combine --metamath-ratio 0.2

# 2. VÃ©rifier le dataset
ls -lh ./data/combined_dataset/train.jsonl

# 3. CrÃ©er la config (si pas dÃ©jÃ  fait)
cp configs/sft_lora_custom.yaml configs/sft_lora_combined.yaml
# Ã‰diter: dataset_name: ./data/combined_dataset

# 4. Lancer le fine-tuning
python sft_train.py configs/sft_lora_combined.yaml

# 5. Tester le nouveau modÃ¨le
./test.sh --model Apertus-FT/output/apertus_lora_combined_* --compare --benchmark
```

---

## ğŸ’¡ Conseils

1. **Commencez petit:** 10K exemples suffisent pour voir l'amÃ©lioration
2. **Testez rapidement:** Utilisez `--question` pour tester le problÃ¨me de trains
3. **Comparez:** Utilisez `--compare` pour voir la diffÃ©rence avec BASE
4. **ItÃ©rez:** Si pas assez bon, augmentez le ratio ou les epochs
5. **Documentez:** Notez les hyperparamÃ¨tres qui fonctionnent

---

## ğŸš€ Quick Start

```bash
# Tout en une commande
python prepare_metamath_dataset.py --ratio 0.2 --max-samples 10000 --combine && \
python sft_train.py configs/sft_lora_combined.yaml
```

Votre modÃ¨le devrait maintenant rÃ©soudre correctement le problÃ¨me de trains! ğŸ¯
