# Dataset Preparation Guide

## üìä Option C - Mix Diversifi√© (Recommand√©)

### R√©partition
```
60% Cybers√©curit√©:
  ‚îú‚îÄ 40% All Sources Deduplicated (mix cyber optimal)
  ‚îî‚îÄ 20% GDPR/Privacy (all_DPO_sources)

40% Diversification:
  ‚îú‚îÄ 25% Nvidia Science Reasoning
  ‚îú‚îÄ 10% Code (CodeAlpaca)
  ‚îî‚îÄ  5% Cr√©atif/Chat (Dolly)
```

### Sources Utilis√©es

| Source | Fichier | Taille | Ratio | Description |
|--------|---------|--------|-------|-------------|
| **Cyber Dedup** | `my_datasets/all_sources_deduplicated.jsonl` | 125K | 40% | Mix optimal cybers√©curit√© (CTF + RedTeam + Privacy) |
| **DPO Privacy** | `my_datasets/all_DPO_sources_0.95-dedup.jsonl` | 11K | 20% | Sp√©cialisation GDPR/DPO |
| **Nvidia Science** | `my_datasets/100k_nvidia_science_reasoning_SFT_converted.jsonl` | 100K | 25% | Raisonnement scientifique avec CoT |
| **Code** | HuggingFace: `sahil2801/CodeAlpaca-20k` | 20K | 10% | D√©veloppement logiciel |
| **General** | HuggingFace: `databricks/databricks-dolly-15k` | 15K | 5% | Chat g√©n√©ral et cr√©ativit√© |

## üöÄ Utilisation

### 1. Cr√©er le Dataset

```bash
# Activer l'environnement
source apertus/bin/activate

# Cr√©er un dataset de 30,000 exemples (recommand√©)
python3 prepare_custom_mix_dataset.py --target-total 30000

# Cr√©er un dataset plus petit pour test
python3 prepare_custom_mix_dataset.py --target-total 5000 --output ./data/test_mix

# Avec seed personnalis√©
python3 prepare_custom_mix_dataset.py --target-total 30000 --seed 12345
```

### 2. Validation Automatique

Le script valide automatiquement que chaque source a suffisamment d'exemples :

```bash
# Exemple : Trop d'exemples demand√©s
python3 prepare_custom_mix_dataset.py --target-total 200000
# ‚ùå VALIDATION √âCHOU√âE
# ‚ùå dpo_privacy: Insuffisant (11,018 < 40,000)
```

**Limites actuelles** (bas√©es sur les sources disponibles) :
- **Maximum th√©orique** : ~55K exemples (limit√© par dpo_privacy: 11K √ó 5 = 55K)
- **Recommand√©** : 20K - 40K exemples

### 3. Configuration du Fine-tuning

Le dataset est automatiquement configur√© dans `configs/sft_lora_combined.yaml` :

```yaml
dataset_name: ./data/custom_mix_dataset_hf
```

### 4. Lancer le Fine-tuning

```bash
apertus sft configs/sft_lora_combined.yaml
```

## üìÅ Structure des Fichiers G√©n√©r√©s

```
data/
‚îú‚îÄ‚îÄ custom_mix_dataset/
‚îÇ   ‚îî‚îÄ‚îÄ train.jsonl                    # Format JSONL brut (121MB pour 30K)
‚îî‚îÄ‚îÄ custom_mix_dataset_hf/
    ‚îú‚îÄ‚îÄ dataset_dict.json              # M√©tadonn√©es HuggingFace
    ‚îú‚îÄ‚îÄ train/                         # Split d'entra√Ænement (90%)
    ‚îÇ   ‚îú‚îÄ‚îÄ data-00000-of-00001.arrow
    ‚îÇ   ‚îú‚îÄ‚îÄ dataset_info.json
    ‚îÇ   ‚îî‚îÄ‚îÄ state.json
    ‚îî‚îÄ‚îÄ test/                          # Split de test (10%)
        ‚îú‚îÄ‚îÄ data-00000-of-00001.arrow
        ‚îú‚îÄ‚îÄ dataset_info.json
        ‚îî‚îÄ‚îÄ state.json
```

## üîç V√©rification du Dataset

### Statistiques Rapides

```bash
source apertus/bin/activate

python3 -c "
import json
from collections import Counter

with open('data/custom_mix_dataset/train.jsonl', 'r') as f:
    data = [json.loads(line) for line in f if line.strip()]

sources = Counter(item.get('source', 'unknown') for item in data)
total = len(data)

print(f'Total: {total:,} exemples\n')
for src, count in sorted(sources.items()):
    print(f'{src:20} {count:6,} ({count/total*100:5.1f}%)')
"
```

### Visualiser des Exemples

```bash
python3 -c "
import json

with open('data/custom_mix_dataset/train.jsonl', 'r') as f:
    for i in range(3):
        line = f.readline()
        data = json.loads(line)

        print(f'\n=== Exemple {i+1} - Source: {data.get(\"source\")} ===')
        for msg in data['messages']:
            print(f'{msg[\"role\"].upper()}: {msg[\"content\"][:100]}...')
"
```

## üéØ Calcul des Nombres Cibles

Pour calculer combien d'exemples demander selon vos besoins :

| Total Cible | Cyber Dedup | DPO Privacy | Nvidia Science | Code | General |
|-------------|-------------|-------------|----------------|------|---------|
| 10,000 | 4,000 | 2,000 | 2,500 | 1,000 | 500 |
| 20,000 | 8,000 | 4,000 | 5,000 | 2,000 | 1,000 |
| 30,000 | 12,000 | 6,000 | 7,500 | 3,000 | 1,500 |
| 40,000 | 16,000 | 8,000 | 10,000 | 4,000 | 2,000 |
| 50,000 | 20,000 | 10,000 | 12,500 | 5,000 | 2,500 |

**‚ö†Ô∏è Limite DPO Privacy** : Maximum 11,018 exemples disponibles, donc le total ne peut pas d√©passer **55,090 exemples** (11,018 √∑ 0.20).

## üõ†Ô∏è Scripts Disponibles

### 1. `prepare_custom_mix_dataset.py` (Option C - Recommand√©)
Mix optimis√© avec validation automatique et vos datasets custom.

**Usage** :
```bash
python3 prepare_custom_mix_dataset.py --target-total 30000
```

### 2. `prepare_diversified_dataset.py` (Option G√©n√©rique)
Mix avec datasets HuggingFace publics (MetaMathQA, CodeAlpaca, Dolly).

**Usage** :
```bash
python3 prepare_diversified_dataset.py \
  --cybersec my_datasets/all_DPO_sources_0.95-dedup.jsonl \
  --target-total 10000
```

### 3. Scripts Legacy
- `prepare_dataset.py` - Conversion dataset GDPR simple
- `prepare_metamath_dataset.py` - Pr√©paration MetaMathQA
- `prepare_combined_dataset.py` - Combinaison GDPR + MetaMathQA

## üìà Monitoring du Training

Apr√®s le fine-tuning, visualisez les m√©triques :

```bash
python3 plot_training_logs.py
```

G√©n√®re :
- `training_metrics.png` - Vue d'ensemble (loss, accuracy, learning rate, etc.)
- `training_loss.png` - Focus sur l'√©volution de la loss

## üí° Conseils

1. **Premi√®re fois** : Commencez avec 5K-10K exemples pour tester rapidement
2. **Production** : Utilisez 30K-40K exemples pour un mod√®le √©quilibr√©
3. **Maximum qualit√©** : Utilisez 50K+ exemples si vous avez plus de donn√©es DPO
4. **Seed fixe** : Gardez le m√™me seed (`--seed 42`) pour la reproductibilit√©

## üîß Personnalisation des Ratios

Si vous voulez ajuster les ratios, modifiez dans `prepare_custom_mix_dataset.py` :

```python
sources = [
    DatasetSource(name="cyber_dedup", path="...", ratio=0.40),  # 40%
    DatasetSource(name="dpo_privacy", path="...", ratio=0.20),  # 20%
    DatasetSource(name="nvidia_science", path="...", ratio=0.25), # 25%
    DatasetSource(name="code", path="...", ratio=0.10),         # 10%
    DatasetSource(name="general", path="...", ratio=0.05),      # 5%
]
```

**Important** : Les ratios doivent sommer √† 1.0 (100%).

## üìö Format des Messages

Tous les exemples sont convertis au format standard :

```json
{
  "messages": [
    {"role": "system", "content": "System prompt adapt√© √† la source..."},
    {"role": "user", "content": "Question de l'utilisateur..."},
    {"role": "assistant", "content": "R√©ponse du mod√®le..."}
  ],
  "source": "cyber_dedup|dpo_privacy|nvidia_science|code|general"
}
```

## üéì System Prompts par Source

| Source | System Prompt |
|--------|---------------|
| **cyber_dedup** | "You are an advanced cybersecurity expert specialized in offensive security, red teaming, and threat analysis." |
| **dpo_privacy** | "You are a helpful AI assistant specialized in data protection, privacy compliance, and GDPR regulations." |
| **nvidia_science** | "You are a helpful AI assistant specialized in scientific reasoning and problem-solving. Think step by step and provide detailed explanations." |
| **code** | "You are a helpful AI assistant specialized in software development and coding. Provide clear, efficient, and well-documented code solutions." |
| **general** | "You are a helpful, creative, and knowledgeable AI assistant. Provide informative and engaging responses." |

## üêõ Troubleshooting

### Erreur : "Insuffisant (X < Y)"
**Probl√®me** : Une source n'a pas assez d'exemples.
**Solution** : R√©duisez `--target-total` ou ajoutez plus de donn√©es sources.

### Erreur : "Fichier introuvable"
**Probl√®me** : Le chemin vers un dataset est incorrect.
**Solution** : V√©rifiez les chemins avec `--cyber-dedup`, `--dpo-sources`, `--nvidia-reasoning`.

### Dataset vide ou incomplet
**Probl√®me** : Format des donn√©es source incorrect.
**Solution** : V√©rifiez que vos JSONL ont le bon format avec les exemples dans le script.

---

**Derni√®re mise √† jour** : 2025-11-07
**Version** : Option C - Mix Diversifi√© avec Validation
