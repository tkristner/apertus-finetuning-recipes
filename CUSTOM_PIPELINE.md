# ğŸ”§ Custom Dataset Pipeline

Pipeline optimisÃ©e pour crÃ©er des datasets mixÃ©s personnalisÃ©s pour le fine-tuning d'Apertus.

## ğŸ¯ Vue d'Ensemble

Cette pipeline implÃ©mente l'**Option C** - un mix diversifiÃ© optimisÃ© :

```
60% CybersÃ©curitÃ© (expertise mÃ©tier)
  â”œâ”€ 40% All Sources Deduplicated    # Mix cyber optimal
  â””â”€ 20% GDPR/Privacy                 # SpÃ©cialisation DPO

40% Diversification (capacitÃ©s gÃ©nÃ©rales)
  â”œâ”€ 25% Nvidia Science Reasoning     # Raisonnement scientifique
  â”œâ”€ 10% Code (CodeAlpaca)            # DÃ©veloppement logiciel
  â””â”€  5% GÃ©nÃ©ral (Dolly)              # Chat gÃ©nÃ©ral
```

## ğŸš€ Quick Start

### 1. CrÃ©er le dataset

```bash
# Activer l'environnement
source apertus/bin/activate

# CrÃ©er 30,000 exemples (recommandÃ© pour production)
python3 prepare_custom_mix_dataset.py --target-total 30000

# Ou crÃ©er 5,000 exemples (pour test rapide)
python3 prepare_custom_mix_dataset.py --target-total 5000
```

### 2. Lancer le fine-tuning

```bash
# Le dataset est dÃ©jÃ  configurÃ©
apertus sft configs/sft_lora_combined.yaml
```

### 3. Visualiser les rÃ©sultats

```bash
python3 plot_training_logs.py
```

## ğŸ“Š Sources de DonnÃ©es

| Source | Fichier | Taille | Ratio | Description |
|--------|---------|--------|-------|-------------|
| **Cyber Dedup** | `my_datasets/all_sources_deduplicated.jsonl` | 126K | 40% | Mix cybersÃ©curitÃ© dÃ©dupliquÃ© |
| **DPO Privacy** | `my_datasets/all_DPO_sources_0.95-dedup.jsonl` | 11K | 20% | GDPR/Privacy/DPO |
| **Nvidia Science** | `my_datasets/100k_nvidia_science_reasoning_SFT_converted.jsonl` | 100K | 25% | Raisonnement scientifique |
| **Code** | HuggingFace: `sahil2801/CodeAlpaca-20k` | 20K | 10% | DÃ©veloppement |
| **General** | HuggingFace: `databricks/databricks-dolly-15k` | 15K | 5% | Chat gÃ©nÃ©ral |

**Limite** : Maximum ~55,000 exemples (limitÃ© par la source DPO Privacy : 11K Ã· 0.20 = 55K)

## âœ… FonctionnalitÃ©s

### Validation Automatique

Le script valide que chaque source a assez d'exemples **avant** de crÃ©er le dataset :

```bash
$ python3 prepare_custom_mix_dataset.py --target-total 200000

ğŸ” VALIDATION DES SOURCES
======================================================================
âœ… cyber_dedup      - Requis: 80,000  | Disponible: 125,574
âŒ dpo_privacy      - Requis: 40,000  | Disponible: 11,018  âŒ
âœ… nvidia_science   - Requis: 50,000  | Disponible: 100,000
âœ… code             - Requis: 20,000  | Disponible: 20,000
âœ… general          - Requis: 10,000  | Disponible: 15,000

âŒ VALIDATION Ã‰CHOUÃ‰E
âŒ dpo_privacy: Insuffisant (11,018 < 40,000)

ğŸ’¡ Solutions:
   1. RÃ©duire le nombre total d'exemples (--target-total)
   2. Ajuster les ratios
   3. Ajouter plus de donnÃ©es sources
```

### Conversion Automatique

Tous les formats sont convertis automatiquement vers le format `messages` :

```json
{
  "messages": [
    {"role": "system", "content": "System prompt adaptÃ©..."},
    {"role": "user", "content": "Question..."},
    {"role": "assistant", "content": "RÃ©ponse..."}
  ],
  "source": "cyber_dedup|dpo_privacy|nvidia_science|code|general"
}
```

## ğŸ› ï¸ Usage DÃ©taillÃ©

### Options de Base

```bash
# Basique
python3 prepare_custom_mix_dataset.py --target-total 30000

# Avec rÃ©pertoire de sortie personnalisÃ©
python3 prepare_custom_mix_dataset.py \
  --target-total 30000 \
  --output ./data/my_custom_mix

# Avec seed pour reproductibilitÃ©
python3 prepare_custom_mix_dataset.py \
  --target-total 30000 \
  --seed 12345
```

### Options AvancÃ©es

```bash
# SpÃ©cifier les chemins des sources explicitement
python3 prepare_custom_mix_dataset.py \
  --target-total 30000 \
  --cyber-dedup /path/to/all_sources_deduplicated.jsonl \
  --dpo-sources /path/to/all_DPO_sources_0.95-dedup.jsonl \
  --nvidia-reasoning /path/to/nvidia_science.jsonl
```

### ParamÃ¨tres

| ParamÃ¨tre | Type | Description | DÃ©faut |
|-----------|------|-------------|--------|
| `--target-total` | int | **Requis** - Nombre total d'exemples | - |
| `--output` | str | RÃ©pertoire de sortie | `./data/custom_mix_dataset` |
| `--seed` | int | Seed pour reproductibilitÃ© | `42` |
| `--cyber-dedup` | str | Chemin vers all_sources_deduplicated.jsonl | `my_datasets/...` |
| `--dpo-sources` | str | Chemin vers all_DPO_sources_0.95-dedup.jsonl | `my_datasets/...` |
| `--nvidia-reasoning` | str | Chemin vers nvidia science dataset | `my_datasets/...` |

## ğŸ“ˆ Calcul des Nombres

Pour calculer combien d'exemples seront utilisÃ©s par source :

| Total | Cyber Dedup (40%) | DPO (20%) | Nvidia (25%) | Code (10%) | General (5%) |
|-------|-------------------|-----------|--------------|------------|--------------|
| 5,000 | 2,000 | 1,000 | 1,250 | 500 | 250 |
| 10,000 | 4,000 | 2,000 | 2,500 | 1,000 | 500 |
| 20,000 | 8,000 | 4,000 | 5,000 | 2,000 | 1,000 |
| 30,000 | 12,000 | 6,000 | 7,500 | 3,000 | 1,500 |
| 40,000 | 16,000 | 8,000 | 10,000 | 4,000 | 2,000 |
| 50,000 | 20,000 | 10,000 | 12,500 | 5,000 | 2,500 |
| **55,000** | **22,000** | **11,000** âš ï¸ | **13,750** | **5,500** | **2,750** |

âš ï¸ **Limite DPO** : Au-delÃ  de 55K, la source DPO Privacy sera insuffisante.

## ğŸ“ Structure GÃ©nÃ©rÃ©e

```
data/
â”œâ”€â”€ custom_mix_dataset/
â”‚   â””â”€â”€ train.jsonl              # Format JSONL brut (~4MB/1000 exemples)
â””â”€â”€ custom_mix_dataset_hf/       # Format HuggingFace
    â”œâ”€â”€ dataset_dict.json
    â”œâ”€â”€ train/                   # 90% des donnÃ©es
    â”‚   â”œâ”€â”€ data-00000-of-00001.arrow
    â”‚   â”œâ”€â”€ dataset_info.json
    â”‚   â””â”€â”€ state.json
    â””â”€â”€ test/                    # 10% des donnÃ©es
        â”œâ”€â”€ data-00000-of-00001.arrow
        â”œâ”€â”€ dataset_info.json
        â””â”€â”€ state.json
```

## ğŸ” VÃ©rification du Dataset

### Statistiques

```bash
python3 -c "
import json
from collections import Counter

with open('data/custom_mix_dataset/train.jsonl', 'r') as f:
    data = [json.loads(line) for line in f if line.strip()]

sources = Counter(item.get('source', 'unknown') for item in data)
total = len(data)

print(f'Total: {total:,} exemples\n')
for src, count in sorted(sources.items()):
    print(f'{src:20} {count:6,} ({count/total*100:5.1f}%)')
"
```

### Visualiser des Exemples

```bash
python3 -c "
import json

with open('data/custom_mix_dataset/train.jsonl', 'r') as f:
    for i in range(3):
        data = json.loads(f.readline())
        print(f'\n=== {data.get(\"source\")} ===')
        for msg in data['messages']:
            print(f'{msg[\"role\"].upper()}: {msg[\"content\"][:80]}...')
"
```

## ğŸ“ System Prompts

Chaque source utilise un system prompt adaptÃ© Ã  son domaine :

| Source | System Prompt |
|--------|---------------|
| **cyber_dedup** | "You are an advanced cybersecurity expert specialized in offensive security, red teaming, and threat analysis." |
| **dpo_privacy** | "You are a helpful AI assistant specialized in data protection, privacy compliance, and GDPR regulations." |
| **nvidia_science** | "You are a helpful AI assistant specialized in scientific reasoning and problem-solving. Think step by step..." |
| **code** | "You are a helpful AI assistant specialized in software development and coding..." |
| **general** | "You are a helpful, creative, and knowledgeable AI assistant..." |

## ğŸ”§ Personnalisation

### Ajuster les Ratios

Pour modifier les ratios, Ã©ditez `prepare_custom_mix_dataset.py` (lignes 655-685) :

```python
sources = [
    DatasetSource(name="cyber_dedup", path="...", ratio=0.40),  # 40%
    DatasetSource(name="dpo_privacy", path="...", ratio=0.20),  # 20%
    DatasetSource(name="nvidia_science", path="...", ratio=0.25), # 25%
    DatasetSource(name="code", path="...", ratio=0.10),         # 10%
    DatasetSource(name="general", path="...", ratio=0.05),      # 5%
]
```

âš ï¸ **Important** : Les ratios doivent sommer Ã  1.0 (100%)

### Ajouter une Nouvelle Source

1. CrÃ©ez un nouveau `DatasetSource` dans la fonction `main()`
2. ImplÃ©mentez la logique de chargement dans `load_local_jsonl()` ou `load_huggingface_dataset()`
3. Ajustez les ratios pour qu'ils somment Ã  1.0

## ğŸ› Troubleshooting

### âŒ "Insuffisant (X < Y)"

**ProblÃ¨me** : Une source n'a pas assez d'exemples.

**Solutions** :
```bash
# Option 1: RÃ©duire le nombre total
python3 prepare_custom_mix_dataset.py --target-total 20000  # au lieu de 50000

# Option 2: VÃ©rifier que les fichiers sources existent
ls -lh my_datasets/

# Option 3: Ajouter plus de donnÃ©es Ã  la source problÃ©matique
```

### âŒ "Fichier introuvable"

**ProblÃ¨me** : Les chemins par dÃ©faut ne correspondent pas Ã  votre structure.

**Solution** : SpÃ©cifiez les chemins explicitement :
```bash
python3 prepare_custom_mix_dataset.py \
  --target-total 30000 \
  --cyber-dedup /correct/path/to/all_sources_deduplicated.jsonl \
  --dpo-sources /correct/path/to/all_DPO_sources_0.95-dedup.jsonl
```

### âš ï¸ Dataset vide ou incomplet

**ProblÃ¨me** : Format des donnÃ©es source incorrect.

**Solution** : VÃ©rifiez le format de vos fichiers JSONL :
```bash
# Doit Ãªtre du JSONL valide (1 JSON par ligne)
head -1 my_datasets/all_sources_deduplicated.jsonl | python3 -m json.tool
```

## ğŸ“Š Workflow Complet

### DÃ©veloppement / Test

```bash
# 1. Test rapide avec petit dataset
python3 prepare_custom_mix_dataset.py --target-total 1000

# 2. VÃ©rifier les statistiques
python3 -c "
import json
with open('data/custom_mix_dataset/train.jsonl') as f:
    print(f'Total: {sum(1 for _ in f):,}')
"

# 3. Fine-tuning rapide (modifiez num_train_epochs: 0.1 dans la config)
apertus sft configs/sft_lora_combined.yaml

# 4. VÃ©rifier que tout fonctionne
python3 plot_training_logs.py
```

### Production

```bash
# 1. CrÃ©er le dataset complet
python3 prepare_custom_mix_dataset.py --target-total 30000

# 2. Valider le dataset
python3 -c "
import json
from collections import Counter
with open('data/custom_mix_dataset/train.jsonl') as f:
    data = [json.loads(line) for line in f]
sources = Counter(d.get('source') for d in data)
print(f'Total: {len(data):,}')
for s, c in sources.items():
    print(f'{s}: {c:,} ({c/len(data)*100:.1f}%)')
"

# 3. Fine-tuning complet
apertus sft configs/sft_lora_combined.yaml

# 4. Analyser les rÃ©sultats
python3 plot_training_logs.py
```

## ğŸ“š Documentation ComplÃ¨te

- **[DATASET_PREPARATION.md](DATASET_PREPARATION.md)** - Guide dÃ©taillÃ© sur les datasets
- **[README.md](README.md)** - Documentation gÃ©nÃ©rale Apertus
- **[configs/sft_lora_combined.yaml](configs/sft_lora_combined.yaml)** - Configuration du fine-tuning

## ğŸ—‚ï¸ Scripts Legacy (ArchivÃ©s)

Les anciens scripts ont Ã©tÃ© dÃ©placÃ©s dans `.archive_old_scripts/` et ne sont plus utilisÃ©s :

- `prepare_dataset.py` - Conversion simple GDPR
- `prepare_metamath_dataset.py` - PrÃ©paration MetaMathQA seul
- `prepare_combined_dataset.py` - Mix GDPR + MetaMathQA
- `prepare_diversified_dataset.py` - Version test gÃ©nÃ©rique

**Ne pas utiliser ces scripts** - ils sont conservÃ©s uniquement pour rÃ©fÃ©rence historique.

## ğŸ’¡ Conseils

1. **PremiÃ¨re utilisation** : Commencez avec `--target-total 5000` pour tester rapidement
2. **Production** : Utilisez 30,000-40,000 exemples pour un Ã©quilibre optimal
3. **ReproductibilitÃ©** : Gardez le mÃªme `--seed` pour des rÃ©sultats identiques
4. **Monitoring** : Utilisez `plot_training_logs.py` aprÃ¨s chaque fine-tuning

## ğŸ“Š MÃ©triques Attendues

Avec un dataset de 30K exemples et la config actuelle :

- **Training time** : ~4-6 heures sur GPU 40GB
- **Loss initiale** : ~1.8
- **Loss finale** : ~1.0-1.1
- **Token accuracy** : +10-15% d'amÃ©lioration
- **Taille du dataset** : ~240MB (HuggingFace format)

---

**Version** : 2.0 - Option C (Mix OptimisÃ©)
**DerniÃ¨re mise Ã  jour** : 2025-11-07
**Script principal** : `prepare_custom_mix_dataset.py`
